# ğŸ¡ House Prices - Advanced Regression Techniques

Predict the final sale prices for homes in **Ames, Iowa** using advanced regression techniques, feature engineering, and model ensembling.  
This project is based on the Kaggle competition: [House Prices - Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques).

---

## ğŸ“Œ Project Overview

This project demonstrates:

- âœ… Data preprocessing and cleaning  
- ğŸ“Š Exploratory Data Analysis (EDA)  
- ğŸ› ï¸ Feature engineering  
- ğŸ¤– Model building with **Random Forest** and **XGBoost**  
- ğŸ” Ensembling and submission generation  

---

## ğŸ“‚ Dataset

The dataset includes the following files:

- `train.csv` â€” Training data with features and target variable (`SalePrice`)  
- `test.csv` â€” Test data to generate predictions  
- `sample_submission.csv` â€” Submission format for Kaggle  
- `data_description.txt` â€” Detailed explanation of each feature  

ğŸ“„ See `data_description.txt` for comprehensive descriptions of all features.

---

## ğŸš€ Getting Started

### âœ… Prerequisites

- Python 3.7 or higher  
- Jupyter Notebook or Google Colab  
- Install required libraries:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost
```

## ğŸ“ Files to Include
Before running the notebook, ensure that the following files are present in your working directory:

- âœ… train.csv
- âœ… test.csv
- âœ… sample_submission.csv
- âœ… data_description.txt
- âœ… house_prices_regression.ipynb

You can download these from the Kaggle competition page.

## ğŸ“’ Running the Notebook
- 1.Open house_prices_regression.ipynb in Jupyter Notebook or Google Colab.
- 2.Run all cells in order to:

-- ğŸ“¥ Load and preprocess the data
-- ğŸ” Perform EDA and feature engineering
-- ğŸ¤– Train Random Forest and XGBoost regression models
-- ğŸ“ˆ Generate predictions on the test data
-- ğŸ’¾ Create submission.csv in the required Kaggle format

##ğŸŒŸ Feature Highlights
- Data Cleaning: Handles missing values and encodes categorical variables
- Feature Engineering: Adds new features like TotalSF (total square footage)
- Modeling: Implements regression using Random Forest and XGBoost
- Ensembling: Averages outputs from multiple models for improved accuracy
- Submission: Exports predictions in Kaggle submission format
